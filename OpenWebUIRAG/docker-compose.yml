version: '3.8'
#This version comes without ollama container, you can install ollama directly on your host
services:
  # Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped
    networks:
      - openwebui-network

  # Apache Tika Server
  tika:
    image: apache/tika:latest
    container_name: tika
    ports:
      - "9998:9998"
    restart: unless-stopped
    networks:
      - openwebui-network

  # Open WebUI
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    ports:
      - "3000:8080"
    volumes:
      - open-webui_data:/app/backend/data
      - ./ebooks:/app/backend/data/docs
    environment:
      # Use host gateway IP to access host Ollama
      - OLLAMA_BASE_URL=http://192.168.1.155:11434

      # Qdrant Configuration
      - VECTOR_DB=qdrant
      - QDRANT_URI=http://qdrant:6333

      # Apache Tika Configuration
      - TIKA_SERVER_URL=http://tika:9998

      # RAG Settings
      - RAG_EMBEDDING_MODEL=nomic-embed-text:latest
      - RAG_TOP_K=5
      - RAG_RELEVANCE_THRESHOLD=0.5
      - CHUNK_SIZE=1500
      - CHUNK_OVERLAP=100

      # Document Upload Settings
      - ENABLE_RAG_WEB_SEARCH=false
      - ENABLE_RAG_LOCAL_WEB_FETCH=true
      - PDF_EXTRACT_IMAGES=true

      # Authentication
      - WEBUI_AUTH=false

      # Other settings
      - WEBUI_NAME="My eBook RAG"
      - DEFAULT_MODELS=llama3.2:latest

    depends_on:
      - qdrant
      - tika
    restart: unless-stopped
    networks:
      - openwebui-network

volumes:
  qdrant_storage:
    driver: local
  open-webui_data:
    driver: local

networks:
  openwebui-network:
    driver: bridge
